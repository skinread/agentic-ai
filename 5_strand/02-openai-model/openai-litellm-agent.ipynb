{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using OpenAI models with Strands Agent\n",
    "\n",
    "## Overview\n",
    "\n",
    "Strands Agents is an SDK that takes a model-driven approach to building and running AI agents in just a few lines of code. Strands supports multiple providers and models hosted anywhere.\n",
    "\n",
    "[LiteLLM](https://docs.litellm.ai/docs/) is a unified interface for various LLM providers that allows you to interact with models from Amazon, Anthropic, OpenAI, and many others through a single API. The Strands Agent SDK implements a LiteLLM provider, allowing you to run agents against any model LiteLLM supports.\n",
    "\n",
    "In this example, we will show you how to use `gpt-4.0-mini` model as the underlying model in your Strands Agent. We will use a simple agent use case with a weather and a get time tool.\n",
    "\n",
    "\n",
    "## Agent Details\n",
    "<div style=\"float: left; margin-right: 20px;\">\n",
    "    \n",
    "|Feature             |Description                                        |\n",
    "|--------------------|---------------------------------------------------|\n",
    "|Feature used        |LiteLLM model                                      |\n",
    "|Agent Structure     |Single agent architecture                          |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/architecture.png\" width=\"65%\" />\n",
    "</div>\n",
    "\n",
    "## Key Features\n",
    "* **LiteLLM model**: using a model provided via LiteLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and prerequisites\n",
    "\n",
    "### Prerequisites\n",
    "* Python 3.10+\n",
    "* Open AI APi Key\n",
    "* gpt-4.0-mini access\n",
    "\n",
    "Let's now install the requirement packages for our Strands Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.5 environment at: e:\\OneDrive\\OneDriveOnitbuddy\\OneDrive\\workbench\\exampletest\\agenticAIeducation\\.venv\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m95 packages\u001b[0m \u001b[2min 2.10s\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 46ms\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 1.83s\u001b[0m\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.11.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.12.15\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlitellm\u001b[0m\u001b[2m==1.72.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# installing pre-requisites\n",
    "!uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dependency packages\n",
    "\n",
    "Now let's import the dependency packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import timezone as tz\n",
    "from typing import Any\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "from strands import Agent, tool\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing your .env variables\n",
    "\n",
    "This will set up the OpenAPI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your OpenAI API key\n",
    "# Method 1: Set environment variable directly\n",
    "import os\n",
    "OPEN_AI_KEY = os.getenv(\"OPENAI_API_KEY\")  # Replace with your actual key\n",
    "\n",
    "\n",
    "# Method 2: Load from .env file (recommended for security)\n",
    "# Create a .env file with: OPENAI_API_KEY=your_actual_key_here\n",
    "# Then the load_dotenv() call below will load it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up custom tools\n",
    "\n",
    "Let's now setup two dummy tools to test our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def current_time(timezone: str = \"UTC\") -> str:\n",
    "    if timezone.upper() == \"UTC\":\n",
    "        timezone_obj: Any = tz.utc\n",
    "    else:\n",
    "        timezone_obj = ZoneInfo(timezone)\n",
    "\n",
    "    return datetime.now(timezone_obj).isoformat()\n",
    "\n",
    "\n",
    "@tool\n",
    "def current_weather(city: str) -> str:\n",
    "    # Dummy implementation. Please replace with actual weather API call.\n",
    "    return \"sunny\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining agent underlying LLM model\n",
    "\n",
    "Next let's define our agent underlying model using LiteLLM. We will set it to `gpt-4.1-mini`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key in environment variable\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key_here\"  # Uncomment and add your key\n",
    "\n",
    "# Create LiteLLM model with string model identifier (not a function!)\n",
    "litellm_model = LiteLLMModel(\n",
    "    model_id=\"gpt-4o-mini\",  # Pass the model name as a string\n",
    "    params={\"max_tokens\": 16383, \"temperature\": 0.7}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Agent\n",
    "\n",
    "Now that we have all the required information available, let's define our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a simple agent that can tell the time and the weather\"\n",
    "agent = Agent(\n",
    "    model=litellm_model,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=[current_time, current_weather],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing agent\n",
    "\n",
    "Let's now invoke the agent to test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: current_time\n",
      "\n",
      "Tool #2: current_weather\n",
      "The current time in Seattle is 7:03 PM, and the weather is sunny."
     ]
    }
   ],
   "source": [
    "results = agent(\"What time is it in Seattle? And how is the weather?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing the agent's results\n",
    "\n",
    "Nice! We've invoked our agent for the first time! Let's now explore the results object. First thing we can see is the messages being exchanged by the agent in the agent's object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': [{'text': 'What time is it in Seattle? And how is the weather?'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'toolUse': {'toolUseId': 'call_khJ2LKZdQWCqCEUwQiVCNgk5',\n",
       "     'name': 'current_time',\n",
       "     'input': {'timezone': 'America/Los_Angeles'}}},\n",
       "   {'toolUse': {'toolUseId': 'call_5cjpKEzXsQvRqIQoAkMaGl1D',\n",
       "     'name': 'current_weather',\n",
       "     'input': {'city': 'Seattle'}}}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'toolResult': {'toolUseId': 'call_khJ2LKZdQWCqCEUwQiVCNgk5',\n",
       "     'status': 'success',\n",
       "     'content': [{'text': '2025-08-07T19:03:46.939818-07:00'}]}},\n",
       "   {'toolResult': {'toolUseId': 'call_5cjpKEzXsQvRqIQoAkMaGl1D',\n",
       "     'status': 'success',\n",
       "     'content': [{'text': 'sunny'}]}}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': 'The current time in Seattle is 7:03 PM, and the weather is sunny.'}]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can take a look at the usage of our agent for the last query by analysing the result `metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventLoopMetrics(cycle_count=2, tool_metrics={'current_weather': ToolMetrics(tool={'toolUseId': 'call_5cjpKEzXsQvRqIQoAkMaGl1D', 'name': 'current_weather', 'input': {'city': 'Seattle'}}, call_count=1, success_count=1, error_count=0, total_time=0.0009012222290039062), 'current_time': ToolMetrics(tool={'toolUseId': 'call_khJ2LKZdQWCqCEUwQiVCNgk5', 'name': 'current_time', 'input': {'timezone': 'America/Los_Angeles'}}, call_count=1, success_count=1, error_count=0, total_time=0.0526118278503418)}, cycle_durations=[1.0967774391174316], traces=[<strands.telemetry.metrics.Trace object at 0x000001C4853F23C0>, <strands.telemetry.metrics.Trace object at 0x000001C4FDF98DD0>], accumulated_usage={'inputTokens': 279, 'outputTokens': 67, 'totalTokens': 346}, accumulated_metrics={'latencyMs': 0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "In this notebook you learned how to use LiteLLM with OpeanAi serving answers for weather agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agents (uv) - Updated",
   "language": "python",
   "name": "agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
