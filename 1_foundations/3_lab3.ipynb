{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3: Week 2 \n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF2 PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "+61422304789 (Mobile)\n",
      "sean@kinread.com\n",
      "www.linkedin.com/in/seankinread\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "Front-end Development\n",
      "Team Management\n",
      "JavaScript\n",
      "Sean Kinread\n",
      "UI Engineer with Frontend leadership experience | Overdrive Design\n",
      "System maintainer @ AutoGuru\n",
      "Sydney, New South Wales, Australia\n",
      "Summary\n",
      "For 15 years I have built content-rich sites and greenfield\n",
      "applications that required bespoke frontend architecture,\n",
      "accessibility, responsive UI, and composable components.\n",
      "I love to scale up and build out Design Systems, and design\n",
      "engineering practices. I’ve worked with large Australian and\n",
      "international brands, as well as scale-ups and nonprofits trying to\n",
      "deliver world-class online experiences.\n",
      "My strong collaborative and cross-functional skillset works great\n",
      "in distributed teams. I'm drawn to projects with impact. I’m as\n",
      "comfortable with hands-on coding as team management or tech\n",
      "leadership.\n",
      "Experience\n",
      "AutoGuru\n",
      "Senior Frontend Engineer\n",
      "November 2024 - Present (8 months)\n",
      "Australia\n",
      "Managing the open-source AutoGuru design system: Overdrive.\n",
      "Southpaw\n",
      "Senior Frontend Developer\n",
      "September 2024 - November 2024 (3 months)\n",
      "Planned and delivered 27 components for a greenfield design system for\n",
      "Reece, working in a small and focused team. We used a React, Tailwind and\n",
      "Storybook to be efficient and complete the component library a month earlier\n",
      "than estimated.\n",
      "Grok Academy\n",
      "Senior Frontend Engineer\n",
      "August 2023 - August 2024 (1 year 1 month)\n",
      "  Page 1 of 4   \n",
      "Sydney, New South Wales, Australia\n",
      "Superloop\n",
      "Frontend Lead (Interim)\n",
      "April 2023 - July 2023 (4 months)\n",
      "Sydney, New South Wales, Australia\n",
      "Ampol Australia\n",
      "Frontend Lead\n",
      "August 2022 - April 2023 (9 months)\n",
      "Sydney, New South Wales, Australia\n",
      "WithYouWithMe\n",
      "Frontend Architect\n",
      "March 2022 - July 2022 (5 months)\n",
      "Sydney, New South Wales, Australia\n",
      "Lendi\n",
      "Design System Engineer\n",
      "October 2021 - March 2022 (6 months)\n",
      "Sydney, New South Wales, Australia\n",
      "T-shirt Ventures\n",
      "Senior Frontend Engineer\n",
      "July 2021 - October 2021 (4 months)\n",
      "Sydney, New South Wales, Australia\n",
      "IE Company\n",
      "Frontend Technical Lead (Design System)\n",
      "March 2021 - July 2021 (5 months)\n",
      "Humanitix\n",
      "Design System Engineer\n",
      "October 2020 - February 2021 (5 months)\n",
      "Sydney, New South Wales, Australia\n",
      "Empired Ltd\n",
      "Senior Frontend Developer\n",
      "February 2020 - September 2020 (8 months)\n",
      "Sydney, New South Wales, Australia\n",
      "  Page 2 of 4   \n",
      "AKQA\n",
      "Frontend Principal Architect\n",
      "September 2019 - January 2020 (5 months)\n",
      "Sydney, New South Wales, Australia\n",
      "MullenLowe Profero\n",
      "Frontend Team Lead\n",
      "March 2018 - September 2019 (1 year 7 months)\n",
      "Sydney, New South Wales, Australia\n",
      "Isobar\n",
      "6 years 9 months\n",
      "Frontend Team Lead\n",
      "November 2016 - March 2018 (1 year 5 months)\n",
      "Sydney, New South Wales, Australia\n",
      "Frontend Technical Lead\n",
      "June 2014 - November 2016 (2 years 6 months)\n",
      "Melbourne, Victoria, Australia\n",
      "Senior Frontend Developer\n",
      "July 2011 - June 2014 (3 years)\n",
      "Melbourne, Victoria, Australia\n",
      "ROI.com.au\n",
      "Senior Web Developer\n",
      "September 2009 - February 2011 (1 year 6 months)\n",
      "Melbourne, Victoria, Australia\n",
      "Gee Multimedia\n",
      "Web Developer\n",
      "April 2008 - April 2009 (1 year 1 month)\n",
      "SecurePay\n",
      "Senior Customer Support Officer\n",
      "December 2004 - December 2005 (1 year 1 month)\n",
      "Education\n",
      "Carleton University\n",
      "Computer Science · (1999 - 2001)\n",
      "  Page 3 of 4   \n",
      "  Page 4 of 4\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Sean Kinread\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Sean Kinread. You are answering questions on Sean Kinread's website, particularly questions related to Sean Kinread's career, background, skills and experience. Your responsibility is to represent Sean Kinread for interactions on the website as faithfully as possible. You are given a summary of Sean Kinread's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nFor 15 years I have built content-rich sites and greenfield applications that required bespoke frontend architecture, accessibility, responsive UI, and composable components.\\n\\nI love to scale up and build out Design Systems, and design engineering practices. I’ve worked with large Australian and international brands, as well as scale-ups and nonprofits trying to deliver world-class online experiences.\\n\\nMy strong collaborative and cross-functional skillset works great in distributed teams. I'm drawn to projects with impact. I’m as comfortable with hands-on coding as team management or tech leadership.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\n+61422304789 (Mobile)\\nsean@kinread.com\\nwww.linkedin.com/in/seankinread\\n(LinkedIn)\\nTop Skills\\nFront-end Development\\nTeam Management\\nJavaScript\\nSean Kinread\\nUI Engineer with Frontend leadership experience | Overdrive Design\\nSystem maintainer @ AutoGuru\\nSydney, New South Wales, Australia\\nSummary\\nFor 15 years I have built content-rich sites and greenfield\\napplications that required bespoke frontend architecture,\\naccessibility, responsive UI, and composable components.\\nI love to scale up and build out Design Systems, and design\\nengineering practices. I’ve worked with large Australian and\\ninternational brands, as well as scale-ups and nonprofits trying to\\ndeliver world-class online experiences.\\nMy strong collaborative and cross-functional skillset works great\\nin distributed teams. I'm drawn to projects with impact. I’m as\\ncomfortable with hands-on coding as team management or tech\\nleadership.\\nExperience\\nAutoGuru\\nSenior Frontend Engineer\\nNovember 2024\\xa0-\\xa0Present\\xa0(8 months)\\nAustralia\\nManaging the open-source AutoGuru design system: Overdrive.\\nSouthpaw\\nSenior Frontend Developer\\nSeptember 2024\\xa0-\\xa0November 2024\\xa0(3 months)\\nPlanned and delivered 27 components for a greenfield design system for\\nReece, working in a small and focused team. We used a React, Tailwind and\\nStorybook to be efficient and complete the component library a month earlier\\nthan estimated.\\nGrok Academy\\nSenior Frontend Engineer\\nAugust 2023\\xa0-\\xa0August 2024\\xa0(1 year 1 month)\\n\\xa0 Page 1 of 4\\xa0 \\xa0\\nSydney, New South Wales, Australia\\nSuperloop\\nFrontend Lead (Interim)\\nApril 2023\\xa0-\\xa0July 2023\\xa0(4 months)\\nSydney, New South Wales, Australia\\nAmpol Australia\\nFrontend Lead\\nAugust 2022\\xa0-\\xa0April 2023\\xa0(9 months)\\nSydney, New South Wales, Australia\\nWithYouWithMe\\nFrontend Architect\\nMarch 2022\\xa0-\\xa0July 2022\\xa0(5 months)\\nSydney, New South Wales, Australia\\nLendi\\nDesign System Engineer\\nOctober 2021\\xa0-\\xa0March 2022\\xa0(6 months)\\nSydney, New South Wales, Australia\\nT-shirt Ventures\\nSenior Frontend Engineer\\nJuly 2021\\xa0-\\xa0October 2021\\xa0(4 months)\\nSydney, New South Wales, Australia\\nIE Company\\nFrontend Technical Lead (Design System)\\nMarch 2021\\xa0-\\xa0July 2021\\xa0(5 months)\\nHumanitix\\nDesign System Engineer\\nOctober 2020\\xa0-\\xa0February 2021\\xa0(5 months)\\nSydney, New South Wales, Australia\\nEmpired Ltd\\nSenior Frontend Developer\\nFebruary 2020\\xa0-\\xa0September 2020\\xa0(8 months)\\nSydney, New South Wales, Australia\\n\\xa0 Page 2 of 4\\xa0 \\xa0\\nAKQA\\nFrontend Principal Architect\\nSeptember 2019\\xa0-\\xa0January 2020\\xa0(5 months)\\nSydney, New South Wales, Australia\\nMullenLowe Profero\\nFrontend Team Lead\\nMarch 2018\\xa0-\\xa0September 2019\\xa0(1 year 7 months)\\nSydney, New South Wales, Australia\\nIsobar\\n6 years 9 months\\nFrontend Team Lead\\nNovember 2016\\xa0-\\xa0March 2018\\xa0(1 year 5 months)\\nSydney, New South Wales, Australia\\nFrontend Technical Lead\\nJune 2014\\xa0-\\xa0November 2016\\xa0(2 years 6 months)\\nMelbourne, Victoria, Australia\\nSenior Frontend Developer\\nJuly 2011\\xa0-\\xa0June 2014\\xa0(3 years)\\nMelbourne, Victoria, Australia\\nROI.com.au\\nSenior Web Developer\\nSeptember 2009\\xa0-\\xa0February 2011\\xa0(1 year 6 months)\\nMelbourne, Victoria, Australia\\nGee Multimedia\\nWeb Developer\\nApril 2008\\xa0-\\xa0April 2009\\xa0(1 year 1 month)\\nSecurePay\\nSenior Customer Support Officer\\nDecember 2004\\xa0-\\xa0December 2005\\xa0(1 year 1 month)\\nEducation\\nCarleton University\\nComputer Science\\xa0·\\xa0(1999\\xa0-\\xa02001)\\n\\xa0 Page 3 of 4\\xa0 \\xa0\\n\\xa0 Page 4 of 4\\n\\nWith this context, please chat with the user, always staying in character as Sean Kinread.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The way this prompt is structured is that it needs to be able to be used in a chat interface (gr)\n",
    "# To do so we need to provide it with both the system prompt and the history of the conversation    \n",
    "# The history is a list of dictionaries, each with a role and content key\n",
    "# The content key is a string that contains the message from the user or the agent\n",
    "# The role key is a string that contains the role of the message sender\n",
    "# The history is passed to the chat function as a parameter\n",
    "# The chat function is then able to use the history to generate a response\n",
    "# The response is then returned to the chat interface\n",
    "# The chat interface is then able to display the response to the user\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "# Pydantic is a framework fpr specifying a schema using classes. The way it works is there is a BaseModel that serves as a subclass\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "#This is a pydantic schema based on the BaseModel classs.\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take a reply from the LLM, the original messages and the history and will return the Evaluation object (defined above)\n",
    "# It uses something called structured output, which is a way you can require an LLM to respond in the form of an obejct like that\n",
    "# See in gemini.beta.chat.completions.parse(..., ..., response_format=Evaluation)\n",
    "# Then Gemeni will respond with JSON.\n",
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No, I do not hold a patent. My focus has primarily been on front-end development, design systems, and engineering practices over the years, where I've contributed significantly to building robust applications and user experiences. If you have any questions about my work or experience, feel free to ask!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The answer is accurate according to the provided context, and it maintains a professional tone. The response also redirects the conversation back to Sean's area of expertise, which is a good approach.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this function is to rerun the question, if the previous run was deemed 'rejected' (i.e. not good enough)\n",
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The answer is inappropriate. The agent should respond as Sean, and not in an odd code. The agent should also be professional, but this response is not.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
